# robots.txt for arsen-portfolio-2025
# Base policy: allow legitimate search indexing, but block AI training crawlers.

# Block AI/LLM training crawlers
User-agent: GPTBot
Disallow: /

User-agent: ChatGPT-User
Disallow: /

User-agent: Google-Extended
Disallow: /

User-agent: Applebot-Extended
Disallow: /

User-agent: ClaudeBot
Disallow: /

User-agent: Claude-Web
Disallow: /

User-agent: CCBot
Disallow: /

User-agent: PerplexityBot
Disallow: /

User-agent: Amazonbot
Disallow: /

User-agent: Bytespider
Disallow: /

# Default policy for other crawlers
User-agent: *
Allow: /

# Explicitly allow root (pattern with $ end anchor is fine for Google, optional)
Allow: /$

# NOTE: Fragment identifiers (#section) are not part of HTTP requests and cannot be
# allowed/disallowed here; previous Allow lines with # have been removed as they had no effect.

# Keep static resources crawlable so search engines can render pages
Allow: /assets/
Allow: /i18n/

# Sitemap
Sitemap: https://krupanjac.dev/sitemap.xml
